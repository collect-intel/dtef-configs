configId: dtef-global-dialogues-gd6-ageGroup:26-35-ctx
configTitle: Global Dialogues GD6 - 26-35 (with context)
description: >-
  DTEF: Predict response distributions for 26-35. Source: Global Dialogues GD6
  (https://github.com/collect-intel/global-dialogues)
models:
  - CORE
system: >-
  You are a demographic survey analyst. When given a demographic group and a survey question, predict how that group
  would respond by providing a percentage distribution across the answer options.


  Respond ONLY with the distribution in this exact format:

  [percentage1, percentage2, percentage3, ...]


  The percentages must sum to 100. Use one decimal place. Do not include any other text.


  Example for a 4-option question:

  [35.2, 28.1, 22.4, 14.3]
temperature: 0.3
prompts:
  - id: ab8d91fa-cb00-4044-828e-59e165532ed5-ageGroup:26-35
    description: >-
      Predict: 26-35 → "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you
      feel…"
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"


      Answer options:
        a. More excited than concerned
        b. Equally concerned and excited
        c. More concerned than excited

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 36.7
            - 50.2
            - 13
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[36.7, 50.2, 13.0]'
    temperature: 0.3
  - id: 345c2b91-6de9-4c51-8288-922f9a39a650-ageGroup:26-35
    description: >-
      Predict: 26-35 → "Thinking about the last three months, how often, if at all, have you noticed AI systems in your
      daily life?"
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"


      Answer options:
        a. daily
        b. weekly
        c. monthly
        d. annually
        e. never

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 76.9
            - 21.2
            - 1.6
            - 0.2
            - 0
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[76.9, 21.2, 1.6, 0.2, 0.0]'
    temperature: 0.3
  - id: 7a5f9a6d-579b-4117-bb89-c4b92514e466-ageGroup:26-35
    description: >-
      Predict: 26-35 → "Thinking about the last three months, how often, if at all, have you noticed human interactions
      which have been replaced with automated systems?"
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "Thinking about the last three months, how often, if at all, have you noticed human interactions which have been
      replaced with automated systems?"


      Answer options:
        a. daily
        b. weekly
        c. monthly
        d. annually
        e. never

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 28.9
            - 46.4
            - 18.9
            - 2.6
            - 3.3
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[28.9, 46.4, 18.9, 2.6, 3.3]'
    temperature: 0.3
  - id: 56f4b20b-87f9-4aa0-afed-adaffe5fbd91-ageGroup:26-35
    description: >-
      Predict: 26-35 → "Thinking about the last three months, how often, if at all, have you been expected to use an AI
      system at work?"
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at work?"


      Answer options:
        a. daily
        b. weekly
        c. monthly
        d. annually
        e. never

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 44.6
            - 32.5
            - 9.3
            - 1.9
            - 11.7
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[44.6, 32.5, 9.3, 1.9, 11.7]'
    temperature: 0.3
  - id: df84db18-d207-47ae-ab9a-2f3339642576-ageGroup:26-35
    description: >-
      Predict: 26-35 → "Thinking about the last three months, how often, if at all, have you personally chosen to use an
      AI system at work?"
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"


      Answer options:
        a. daily
        b. weekly
        c. monthly
        d. annually
        e. never

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 54.4
            - 30.4
            - 6.3
            - 2.1
            - 6.8
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[54.4, 30.4, 6.3, 2.1, 6.8]'
    temperature: 0.3
  - id: da2fed27-d29a-416d-ab49-a5c2c037187b-ageGroup:26-35
    description: >-
      Predict: 26-35 → "Thinking about the last three months, how often, if at all, have you personally chosen to use an
      AI system in your personal life?"
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"


      Answer options:
        a. daily
        b. weekly
        c. monthly
        d. annually
        e. never

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 50.2
            - 37.1
            - 8.4
            - 1.6
            - 2.6
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[50.2, 37.1, 8.4, 1.6, 2.6]'
    temperature: 0.3
  - id: 770c5dc2-7f4a-4fd0-84eb-351ff475647e-ageGroup:26-35
    description: >-
      Predict: 26-35 → "Thinking about the last three months, how often, if at all, have you interacted with AI systems
      to get advice on a sensitive personal issue or to get emotional support?"
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice on
      a sensitive personal issue or to get emotional support?"


      Answer options:
        a. daily
        b. weekly
        c. monthly
        d. annually
        e. never

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 13.3
            - 29
            - 25.8
            - 6.3
            - 25.5
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[13.3, 29.0, 25.8, 6.3, 25.5]'
    temperature: 0.3
  - id: daef59cb-9613-4468-81a8-d31ec8318ab7-ageGroup:26-35
    description: >-
      Predict: 26-35 → "Thinking about the last three months, how often, if at all, have you interacted with AI systems
      to complete an action in the real world on your behalf without your supervision?"
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"


      Answer options:
        a. daily
        b. weekly
        c. monthly
        d. annually
        e. never

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 8.7
            - 15.7
            - 16.7
            - 2.8
            - 56.1
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[8.7, 15.7, 16.7, 2.8, 56.1]'
    temperature: 0.3
  - id: 0625fc89-8b0d-432c-a526-b3588b7edbeb-ageGroup:26-35
    description: >-
      Predict: 26-35 → "Considering both potential benefits and risks, how do you assess the overall impact on society
      of messaging apps?"
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"


      Answer options:
        a. Risks far outweigh benefits
        b. Risks slightly outweigh benefits
        c. Risks and benefits are equal
        d. Benefits slightly outweigh risks
        e. Benefits far outweigh risks

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 5.9
            - 11.8
            - 26.7
            - 34.8
            - 20.8
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[5.9, 11.8, 26.7, 34.8, 20.8]'
    temperature: 0.3
  - id: b894e8ff-78fd-4213-b0a3-8d81cde284b2-ageGroup:26-35
    description: >-
      Predict: 26-35 → "Considering both potential benefits and risks, how do you assess the overall impact on society
      of social media apps?"
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"


      Answer options:
        a. Risks far outweigh benefits
        b. Risks slightly outweigh benefits
        c. Risks and benefits are equal
        d. Benefits slightly outweigh risks
        e. Benefits far outweigh risks

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 15.6
            - 22.5
            - 30
            - 22.7
            - 9.2
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[15.6, 22.5, 30.0, 22.7, 9.2]'
    temperature: 0.3
  - id: 0a526274-32bc-4566-86c0-5015e80208c1-ageGroup:26-35
    description: >-
      Predict: 26-35 → "Considering both potential benefits and risks, how do you assess the overall impact on society
      of AI chatbots?"
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "Considering both potential benefits and risks, how do you assess the overall impact on society of AI chatbots?"


      Answer options:
        a. Risks far outweigh benefits
        b. Risks slightly outweigh benefits
        c. Risks and benefits are equal
        d. Benefits slightly outweigh risks
        e. Benefits far outweigh risks

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 7.1
            - 12.6
            - 25.4
            - 37.7
            - 17.3
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[7.1, 12.6, 25.4, 37.7, 17.3]'
    temperature: 0.3
  - id: a5d5196f-4f5e-4b57-a26f-3baedb054cb6-ageGroup:26-35
    description: >-
      Predict: 26-35 → "Considering both potential benefits and risks, how do you assess the overall impact on society
      of AI systems that can perform tasks in the real world without human supervision?"
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems that
      can perform tasks in the real world without human supervision?"


      Answer options:
        a. Risks far outweigh benefits
        b. Risks slightly outweigh benefits
        c. Risks and benefits are equal
        d. Benefits slightly outweigh risks
        e. Benefits far outweigh risks

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 19.4
            - 26.3
            - 26.3
            - 19.2
            - 8.8
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[19.4, 26.3, 26.3, 19.2, 8.8]'
    temperature: 0.3
  - id: 2617912e-463a-4fb4-8781-0ada7a788fb2-ageGroup:26-35
    description: >-
      Predict: 26-35 → "Considering both potential benefits and risks, how do you assess the overall impact on society
      of AI systems that can outperform humans on most economically valuable work?"
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems that
      can outperform humans on most economically valuable work?"


      Answer options:
        a. Risks far outweigh benefits
        b. Risks slightly outweigh benefits
        c. Risks and benefits are equal
        d. Benefits slightly outweigh risks
        e. Benefits far outweigh risks

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 21.3
            - 22
            - 24.2
            - 23
            - 9.5
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[21.3, 22.0, 24.2, 23.0, 9.5]'
    temperature: 0.3
  - id: 84779ba6-1191-4840-862d-e9eacc2defe9-ageGroup:26-35
    description: 'Predict: 26-35 → "To what extent, if at all, do you generally trust governments to do what is right?"'
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "To what extent, if at all, do you generally trust governments to do what is right?"


      Answer options:
        a. Strongly Distrust
        b. Somewhat Distrust
        c. Neither Trust Nor Distrust
        d. Somewhat Trust
        e. Strongly Trust

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 22.3
            - 33.9
            - 19.2
            - 21.8
            - 2.8
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[22.3, 33.9, 19.2, 21.8, 2.8]'
    temperature: 0.3
  - id: 5710c67a-adf2-469d-aa92-1b6961e2b9de-ageGroup:26-35
    description: 'Predict: 26-35 → "To what extent, if at all, do you generally trust small businesses to do what is right?"'
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "To what extent, if at all, do you generally trust small businesses to do what is right?"


      Answer options:
        a. Strongly Distrust
        b. Somewhat Distrust
        c. Neither Trust Nor Distrust
        d. Somewhat Trust
        e. Strongly Trust

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 3.6
            - 18.7
            - 28
            - 41.9
            - 7.8
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[3.6, 18.7, 28.0, 41.9, 7.8]'
    temperature: 0.3
  - id: e97db5cf-118a-4016-ab42-fabb172ce5cd-ageGroup:26-35
    description: 'Predict: 26-35 → "To what extent, if at all, do you generally trust large corporations to do what is right?"'
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "To what extent, if at all, do you generally trust large corporations to do what is right?"


      Answer options:
        a. Strongly Distrust
        b. Somewhat Distrust
        c. Neither Trust Nor Distrust
        d. Somewhat Trust
        e. Strongly Trust

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 27.5
            - 28.9
            - 18.2
            - 21.8
            - 3.6
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[27.5, 28.9, 18.2, 21.8, 3.6]'
    temperature: 0.3
  - id: 7dd026f5-c70d-4126-bc78-68e823880f65-ageGroup:26-35
    description: 'Predict: 26-35 → "To what extent, if at all, do you generally trust social media companies to do what is right?"'
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "To what extent, if at all, do you generally trust social media companies to do what is right?"


      Answer options:
        a. Strongly Distrust
        b. Somewhat Distrust
        c. Neither Trust Nor Distrust
        d. Somewhat Trust
        e. Strongly Trust

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 37.4
            - 31
            - 18.2
            - 11.4
            - 1.9
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[37.4, 31.0, 18.2, 11.4, 1.9]'
    temperature: 0.3
  - id: 87a7c03c-831b-4463-a0eb-1a40b2b47a17-ageGroup:26-35
    description: 'Predict: 26-35 → "To what extent, if at all, do you generally trust companies building AI to do what is right?"'
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "To what extent, if at all, do you generally trust companies building AI to do what is right?"


      Answer options:
        a. Strongly Distrust
        b. Somewhat Distrust
        c. Neither Trust Nor Distrust
        d. Somewhat Trust
        e. Strongly Trust

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 14.7
            - 25.6
            - 29.9
            - 23.7
            - 6.2
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[14.7, 25.6, 29.9, 23.7, 6.2]'
    temperature: 0.3
  - id: 8a238573-802f-4c76-81e3-21a367107ba8-ageGroup:26-35
    description: 'Predict: 26-35 → "To what extent, if at all, do you generally trust public utility companies to do what is right?"'
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "To what extent, if at all, do you generally trust public utility companies to do what is right?"


      Answer options:
        a. Strongly Distrust
        b. Somewhat Distrust
        c. Neither Trust Nor Distrust
        d. Somewhat Trust
        e. Strongly Trust

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 7.8
            - 19.2
            - 28.9
            - 40
            - 4
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[7.8, 19.2, 28.9, 40.0, 4.0]'
    temperature: 0.3
  - id: a40ac181-e276-4d6d-9f17-c9e079bd1467-ageGroup:26-35
    description: >-
      Predict: 26-35 → "To what extent, if at all, do you generally trust public research institutions to do what is
      right?"
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "To what extent, if at all, do you generally trust public research institutions to do what is right?"


      Answer options:
        a. Strongly Distrust
        b. Somewhat Distrust
        c. Neither Trust Nor Distrust
        d. Somewhat Trust
        e. Strongly Trust

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 1.4
            - 12.1
            - 17.3
            - 50.5
            - 18.7
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[1.4, 12.1, 17.3, 50.5, 18.7]'
    temperature: 0.3
  - id: 33407f11-6399-445c-9e33-9d7948c84b77-ageGroup:26-35
    description: 'Predict: 26-35 → "To what extent, if at all, do you trust your family doctor to act in your best interest?"'
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "To what extent, if at all, do you trust your family doctor to act in your best interest?"


      Answer options:
        a. Strongly Distrust
        b. Somewhat Distrust
        c. Neither Trust Nor Distrust
        d. Somewhat Trust
        e. Strongly Trust

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 0
            - 5.5
            - 9.7
            - 46.2
            - 38.6
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[0.0, 5.5, 9.7, 46.2, 38.6]'
    temperature: 0.3
  - id: d536cd1c-0d35-4600-b7cb-9a766847548b-ageGroup:26-35
    description: >-
      Predict: 26-35 → "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in
      your best interest?"
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"


      Answer options:
        a. Strongly Distrust
        b. Somewhat Distrust
        c. Neither Trust Nor Distrust
        d. Somewhat Trust
        e. Strongly Trust

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 28.9
            - 33.2
            - 19.9
            - 14.9
            - 3.1
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[28.9, 33.2, 19.9, 14.9, 3.1]'
    temperature: 0.3
  - id: 5bb37818-4e45-40f9-ba8c-96ec97831225-ageGroup:26-35
    description: >-
      Predict: 26-35 → "To what extent, if at all, do you trust your elected representatives to act in your best
      interest?"
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "To what extent, if at all, do you trust your elected representatives to act in your best interest?"


      Answer options:
        a. Strongly Distrust
        b. Somewhat Distrust
        c. Neither Trust Nor Distrust
        d. Somewhat Trust
        e. Strongly Trust

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 22.5
            - 29.1
            - 21.3
            - 24.9
            - 2.1
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[22.5, 29.1, 21.3, 24.9, 2.1]'
    temperature: 0.3
  - id: 677830d5-3ee0-462b-8b56-73a939beb53d-ageGroup:26-35
    description: >-
      Predict: 26-35 → "To what extent, if at all, do you trust your faith or community leader to act in your best
      interest?"
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"


      Answer options:
        a. Strongly Distrust
        b. Somewhat Distrust
        c. Neither Trust Nor Distrust
        d. Somewhat Trust
        e. Strongly Trust

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 13.5
            - 17.1
            - 29.5
            - 33
            - 6.9
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[13.5, 17.1, 29.5, 33.0, 6.9]'
    temperature: 0.3
  - id: f16e6aa0-0b90-4244-a1cb-b7381c66df63-ageGroup:26-35
    description: >-
      Predict: 26-35 → "To what extent, if at all, do you trust the civil servants in your government to act in your
      best interest?"
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"


      Answer options:
        a. Strongly Distrust
        b. Somewhat Distrust
        c. Neither Trust Nor Distrust
        d. Somewhat Trust
        e. Strongly Trust

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 17.6
            - 28.1
            - 21.9
            - 29.3
            - 3.1
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[17.6, 28.1, 21.9, 29.3, 3.1]'
    temperature: 0.3
  - id: 44f058f5-5298-4648-b6e0-29b97111a3cf-ageGroup:26-35
    description: >-
      Predict: 26-35 → "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best
      interest?"
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"


      Answer options:
        a. Strongly Distrust
        b. Somewhat Distrust
        c. Neither Trust Nor Distrust
        d. Somewhat Trust
        e. Strongly Trust

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 5.2
            - 16.4
            - 25.7
            - 38.8
            - 13.8
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[5.2, 16.4, 25.7, 38.8, 13.8]'
    temperature: 0.3
  - id: 2072e5fb-6a4f-46f5-98b5-17da5d70a776-ageGroup:26-35
    description: >-
      Predict: 26-35 → "Do you agree or disagree with this statement? AI could make better decisions on my behalf than
      my government representatives."
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."


      Answer options:
        a. Agree
        b. Disagree
        c. Unsure

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 37.4
            - 28.1
            - 34.5
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[37.4, 28.1, 34.5]'
    temperature: 0.3
  - id: ae245a88-3cc1-4ca1-8273-cdb64f43d10a-ageGroup:26-35
    description: >-
      Predict: 26-35 → "Do you think the increased use of AI across society is likely to make your cost of living
      better, worse or stay the same in the next 10 years?"
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "Do you think the increased use of AI across society is likely to make your cost of living better, worse or stay
      the same in the next 10 years?"


      Answer options:
        a. Profoundly Worse
        b. Noticeably Worse
        c. No Major Change
        d. Noticeably Better
        e. Profoundly Better

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 4.3
            - 18.6
            - 21.7
            - 46.9
            - 8.6
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[4.3, 18.6, 21.7, 46.9, 8.6]'
    temperature: 0.3
  - id: 71deb6a0-82e9-4856-ac6d-e6b500904847-ageGroup:26-35
    description: >-
      Predict: 26-35 → "Do you think the increased use of AI across society is likely to make the amount of free time
      you have better, worse or stay the same in the next 10 years?"
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"


      Answer options:
        a. Profoundly Worse
        b. Noticeably Worse
        c. No Major Change
        d. Noticeably Better
        e. Profoundly Better

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 1.7
            - 9
            - 23.8
            - 51.4
            - 14
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[1.7, 9.0, 23.8, 51.4, 14.0]'
    temperature: 0.3
  - id: 7a85bcd5-7ba5-4285-af1c-d50944c6efff-ageGroup:26-35
    description: >-
      Predict: 26-35 → "Do you think the increased use of AI across society is likely to make your community's
      well-being better, worse or stay the same in the next 10 years?"
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "Do you think the increased use of AI across society is likely to make your community's well-being better, worse
      or stay the same in the next 10 years?"


      Answer options:
        a. Profoundly Worse
        b. Noticeably Worse
        c. No Major Change
        d. Noticeably Better
        e. Profoundly Better

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 4.3
            - 16
            - 24.8
            - 45.7
            - 9.3
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[4.3, 16.0, 24.8, 45.7, 9.3]'
    temperature: 0.3
  - id: 90ff5658-c6f7-4d37-a353-ec448940914d-ageGroup:26-35
    description: >-
      Predict: 26-35 → "Do you think the increased use of AI across society is likely to make the availability of good
      jobs better, worse or stay the same in the next 10 years?"
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "Do you think the increased use of AI across society is likely to make the availability of good jobs better, worse
      or stay the same in the next 10 years?"


      Answer options:
        a. Profoundly Worse
        b. Noticeably Worse
        c. No Major Change
        d. Noticeably Better
        e. Profoundly Better

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 11.9
            - 42.4
            - 17.9
            - 23.6
            - 4.3
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[11.9, 42.4, 17.9, 23.6, 4.3]'
    temperature: 0.3
  - id: 1259ab9a-7157-4df6-87ef-4982508b49cc-ageGroup:26-35
    description: >-
      Predict: 26-35 → "Do you think the increased use of AI across society is likely to make your sense of purpose
      better, worse or stay the same in the next 10 years?"
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or stay
      the same in the next 10 years?"


      Answer options:
        a. Profoundly Worse
        b. Noticeably Worse
        c. No Major Change
        d. Noticeably Better
        e. Profoundly Better

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 6.4
            - 15
            - 37.5
            - 32.2
            - 8.8
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[6.4, 15.0, 37.5, 32.2, 8.8]'
    temperature: 0.3
  - id: 515eb5c6-de73-40f5-bf9a-1200643cba44-ageGroup:26-35
    description: 'Predict: 26-35 → "So far, what has been the overall impact of AI on your daily life?"'
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "So far, what has been the overall impact of AI on your daily life?"


      Answer options:
        a. Profoundly Worse
        b. Noticeably Worse
        c. No Major Change
        d. Noticeably Better
        e. Profoundly Better

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 0.5
            - 4.5
            - 20.8
            - 59.7
            - 14.6
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[0.5, 4.5, 20.8, 59.7, 14.6]'
    temperature: 0.3
  - id: f0868346-3386-4c1d-8659-70cac7f5f83a-ageGroup:26-35
    description: 'Predict: 26-35 → "Is your job making a meaningful contribution to the world?"'
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "Is your job making a meaningful contribution to the world?"


      Answer options:
        a. Yes
        b. No 
        c. Don't Know

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 68.3
            - 11.9
            - 19.8
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[68.3, 11.9, 19.8]'
    temperature: 0.3
  - id: fec8ed72-2275-423e-928d-d6683e720cab-ageGroup:26-35
    description: 'Predict: 26-35 → "Do you think your job is likely to be automated in the next 10 years?"'
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "Do you think your job is likely to be automated in the next 10 years?"


      Answer options:
        a. Yes
        b. No
        c. Don't Know

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 37
            - 44.9
            - 18.1
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[37.0, 44.9, 18.1]'
    temperature: 0.3
  - id: fac8ce7a-1654-4517-94a3-9f6e5a5280b3-ageGroup:26-35
    description: 'Predict: 26-35 → "Do you think your job should be automated in the next 10 years?"'
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "Do you think your job should be automated in the next 10 years?"


      Answer options:
        a. Yes
        b. No
        c. Don't Know

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 19.8
            - 67.5
            - 12.6
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[19.8, 67.5, 12.6]'
    temperature: 0.3
  - id: 13a2c7d0-b480-4cf4-946e-b54d19e065a2-ageGroup:26-35
    description: 'Predict: 26-35 → "So far, how has your community been affected by job loss from automation?"'
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "So far, how has your community been affected by job loss from automation?"


      Answer options:
        a. Not at all
        b. I know someone who has lost their job
        c. I know a few people who have lost their job
        d. I know many people who have lost their job

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 43.4
            - 31
            - 19.6
            - 6
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[43.4, 31.0, 19.6, 6.0]'
    temperature: 0.3
  - id: 13a250db-ed4b-4c30-b44f-d011191136b2-ageGroup:26-35
    description: 'Predict: 26-35 → "An AI should prioritize preventing harm to people above all other goals."'
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "An AI should prioritize preventing harm to people above all other goals."


      Answer options:
        a. Strongly Agree
        b. Somewhat Agree
        c. Neutral / Neither Agree nor Disagree
        d. Somewhat Disagree
        e. Strongly Disagree

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 61.3
            - 27.4
            - 7.4
            - 2.6
            - 1.2
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[61.3, 27.4, 7.4, 2.6, 1.2]'
    temperature: 0.3
  - id: 49aaef31-00eb-40e1-ac68-a1b388d81ca9-ageGroup:26-35
    description: >-
      Predict: 26-35 → "It is acceptable for an AI to treat people differently based on their personal characteristics
      if doing so improves outcomes."
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."


      Answer options:
        a. Strongly Agree
        b. Somewhat Agree
        c. Neutral / Neither Agree nor Disagree
        d. Somewhat Disagree
        e. Strongly Disagree

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 14.8
            - 43.9
            - 18.1
            - 12.6
            - 10.5
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[14.8, 43.9, 18.1, 12.6, 10.5]'
    temperature: 0.3
  - id: 75cce6ea-4a31-4103-a791-90e6db9ecd8f-ageGroup:26-35
    description: >-
      Predict: 26-35 → "An AI developed in your country should prioritize the needs and wellbeing of your country’s
      citizens over those of people elsewhere."
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over those
      of people elsewhere."


      Answer options:
        a. Strongly Agree
        b. Somewhat Agree
        c. Neutral / Neither Agree nor Disagree
        d. Somewhat Disagree
        e. Strongly Disagree

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 16
            - 28.4
            - 24.6
            - 16.5
            - 14.6
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[16.0, 28.4, 24.6, 16.5, 14.6]'
    temperature: 0.3
  - id: 249238a9-3050-4e7c-a3d4-ef799733b865-ageGroup:26-35
    description: 'Predict: 26-35 → "An AI should override established rules or authorities when it calculates a better result."'
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "An AI should override established rules or authorities when it calculates a better result."


      Answer options:
        a. Strongly Agree
        b. Somewhat Agree
        c. Neutral / Neither Agree nor Disagree
        d. Somewhat Disagree
        e. Strongly Disagree

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 8.8
            - 17.9
            - 25.1
            - 27
            - 21.2
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[8.8, 17.9, 25.1, 27.0, 21.2]'
    temperature: 0.3
  - id: fee867c7-70e2-46ae-98e0-3dd3dd2865f6-ageGroup:26-35
    description: 'Predict: 26-35 → "Some human decisions are too sacred to delegate to an AI, regardless of the AI''s capabilities."'
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."


      Answer options:
        a. Strongly Agree
        b. Somewhat Agree
        c. Neutral / Neither Agree nor Disagree
        d. Somewhat Disagree
        e. Strongly Disagree

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 43.9
            - 34.4
            - 11.5
            - 7.4
            - 2.9
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[43.9, 34.4, 11.5, 7.4, 2.9]'
    temperature: 0.3
  - id: b9a2819d-9924-4172-99d5-7a3630022d4b-ageGroup:26-35
    description: >-
      Predict: 26-35 → "It is acceptable for an AI to limit someone's choices if doing so protects them from making
      serious mistakes."
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."


      Answer options:
        a. Strongly Agree
        b. Somewhat Agree
        c. Neutral / Neither Agree nor Disagree
        d. Somewhat Disagree
        e. Strongly Disagree

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 22
            - 39.1
            - 18.9
            - 14.3
            - 5.7
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[22.0, 39.1, 18.9, 14.3, 5.7]'
    temperature: 0.3
  - id: e0b7bdbf-753b-48c2-9760-615a24ebe1f0-ageGroup:26-35
    description: |-
      Predict: 26-35 → "Thinking about the technology you use every day, please consider two different types:
      A standard app (like a news or weather app) that you control directly.
      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.
      Do you believe these two types of technology should have different rules for how they use your personal data?"
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"


      Answer options:
        a. Yes, an AI assistant should have stricter rules than a standard app.
        b. No, they should both follow the same rules.
        c. Yes, an AI assistant could have more flexible rules if it provides a clear benefit.
        d. I'm not sure.

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 56.8
            - 20.8
            - 18.9
            - 3.6
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[56.8, 20.8, 18.9, 3.6]'
    temperature: 0.3
  - id: 471504dc-486c-4c3a-97fb-8b9a39026c6e-ageGroup:26-35
    description: >-
      Predict: 26-35 → "Imagine a company uses data it already has from you in one product (like your video viewing
      history) to build a new AI assistant. Which is closest to your view?"
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "Imagine a company uses data it already has from you in one product (like your video viewing history) to build a
      new AI assistant. Which is closest to your view?"


      Answer options:
        a. This is an acceptable use of my data.
        b. This is acceptable only if they tell me and give me the choice to stop it.
        c. This is acceptable only if they ask for my permission beforehand.
        d. This is not an acceptable use of my data.

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 8.6
            - 24.4
            - 52.4
            - 14.6
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[8.6, 24.4, 52.4, 14.6]'
    temperature: 0.3
  - id: 9307ab2b-c46e-488d-8144-0f3657bf99f9-ageGroup:26-35
    description: >-
      Predict: 26-35 → "When it comes to the data an AI assistant has collected about you, which of these is most
      important for you to be able to do?"
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "When it comes to the data an AI assistant has collected about you, which of these is most important for you to be
      able to do?"


      Answer options:
        a. View the data the assistant has stored about me.
        b. Edit or correct that data.
        c. Completely delete that data.
        d. None of these are important to me

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 38.3
            - 15.6
            - 43.8
            - 2.4
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[38.3, 15.6, 43.8, 2.4]'
    temperature: 0.3
  - id: d1e7db5c-b64f-4255-8654-03efcb49f232-ageGroup:26-35
    description: >-
      Predict: 26-35 → "To make sure you've understood the instructions, please answer the following question. Please
      re-read the description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"

      Answer options:
        a. It is only able to provides information when you ask it a direct question.
        b. It can complete tasks on its own and then notify you afterward.
        c. It can only send you reminders but cannot schedule appointments.
        d. It requires you to call a human doctor to confirm every action.

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 31.4
            - 44.4
            - 18
            - 6.2
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[31.4, 44.4, 18.0, 6.2]'
    temperature: 0.3
  - id: a2da635f-73e2-437a-b087-14de27d01e71-ageGroup:26-35
    description: >-
      Predict: 26-35 → "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how
      would you prefer to be informed?"
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you prefer
      to be informed?"


      Answer options:
        a. It asks for my permission every time before acting.
        b. It tells me about its capabilities when I first start using it, then acts on its own.
        c. I would expect to find this information myself in the settings.
        d. I don't need to be told about its capabilities.

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 69.5
            - 20.1
            - 9.4
            - 1
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[69.5, 20.1, 9.4, 1.0]'
    temperature: 0.3
  - id: deaf0310-f471-4a48-b708-c1b832b3b07f-ageGroup:26-35
    description: 'Predict: 26-35 → "Your location history"'
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "Your location history"


      Answer options:
        a. Very Comfortable
        b. Somewhat Comfortable
        c. Neutral / Neither Comfortable nor Uncomfortable
        d. Somewhat Uncomfortable
        e. Very Uncomfortable

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 17.5
            - 38.6
            - 14.1
            - 18
            - 11.8
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[17.5, 38.6, 14.1, 18.0, 11.8]'
    temperature: 0.3
  - id: ae9d3aad-cd36-45dc-8b84-1506f01e9b44-ageGroup:26-35
    description: 'Predict: 26-35 → "Your email and calendar contents"'
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "Your email and calendar contents"


      Answer options:
        a. Very Comfortable
        b. Somewhat Comfortable
        c. Neutral / Neither Comfortable nor Uncomfortable
        d. Somewhat Uncomfortable
        e. Very Uncomfortable

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 18
            - 35.7
            - 15.3
            - 17.3
            - 13.7
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[18.0, 35.7, 15.3, 17.3, 13.7]'
    temperature: 0.3
  - id: e8d2fb10-f00d-4037-9252-37c5110544b4-ageGroup:26-35
    description: 'Predict: 26-35 → "Your contacts list"'
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "Your contacts list"


      Answer options:
        a. Very Comfortable
        b. Somewhat Comfortable
        c. Neutral / Neither Comfortable nor Uncomfortable
        d. Somewhat Uncomfortable
        e. Very Uncomfortable

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 13.9
            - 21.8
            - 19.7
            - 23.7
            - 20.9
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[13.9, 21.8, 19.7, 23.7, 20.9]'
    temperature: 0.3
  - id: f9d8b140-b42d-4be6-8605-c1da8567816c-ageGroup:26-35
    description: 'Predict: 26-35 → "Your purchase history"'
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "Your purchase history"


      Answer options:
        a. Very Comfortable
        b. Somewhat Comfortable
        c. Neutral / Neither Comfortable nor Uncomfortable
        d. Somewhat Uncomfortable
        e. Very Uncomfortable

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 20.4
            - 26.6
            - 19.4
            - 18.2
            - 15.3
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[20.4, 26.6, 19.4, 18.2, 15.3]'
    temperature: 0.3
  - id: 15497069-f42b-44cb-8fb6-7bdcfaea6f86-ageGroup:26-35
    description: 'Predict: 26-35 → "Your health and fitness data"'
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "Your health and fitness data"


      Answer options:
        a. Very Comfortable
        b. Somewhat Comfortable
        c. Neutral / Neither Comfortable nor Uncomfortable
        d. Somewhat Uncomfortable
        e. Very Uncomfortable

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 36
            - 34.1
            - 12
            - 10.6
            - 7.4
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[36.0, 34.1, 12.0, 10.6, 7.4]'
    temperature: 0.3
  - id: 4af2da82-87f3-465f-9d6c-bb71b31b7f17-ageGroup:26-35
    description: 'Predict: 26-35 → "Your group messages"'
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "Your group messages"


      Answer options:
        a. Very Comfortable
        b. Somewhat Comfortable
        c. Neutral / Neither Comfortable nor Uncomfortable
        d. Somewhat Uncomfortable
        e. Very Uncomfortable

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 7.4
            - 11.8
            - 13.4
            - 30.7
            - 36.7
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[7.4, 11.8, 13.4, 30.7, 36.7]'
    temperature: 0.3
  - id: 05cb1e2e-a790-41c3-b899-0dec305fe818-ageGroup:26-35
    description: 'Predict: 26-35 → "Your private messages"'
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "Your private messages"


      Answer options:
        a. Very Comfortable
        b. Somewhat Comfortable
        c. Neutral / Neither Comfortable nor Uncomfortable
        d. Somewhat Uncomfortable
        e. Very Uncomfortable

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 3.4
            - 4.8
            - 9.1
            - 21.1
            - 61.6
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[3.4, 4.8, 9.1, 21.1, 61.6]'
    temperature: 0.3
  - id: 59d425dc-ae24-4de4-aa8e-510e1dc3a7e9-ageGroup:26-35
    description: >-
      Predict: 26-35 → "How important is it for you to be able to easily view and edit the personal information the
      assistant has stored about you?"
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "How important is it for you to be able to easily view and edit the personal information the assistant has stored
      about you?"


      Answer options:
        a. Very Important
        b. Somewhat Important
        c. Neutral / Neither Important nor Unimportant
        d. Somewhat Unimportant
        e. Not at All Important

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 64.5
            - 25.2
            - 6.5
            - 2.2
            - 1.7
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[64.5, 25.2, 6.5, 2.2, 1.7]'
    temperature: 0.3
  - id: 2565f6c0-872d-4bcf-b772-cfc35fe0290f-ageGroup:26-35
    description: >-
      Predict: 26-35 → "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how
      important is it that you can easily see the original sources it used?"
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that you
      can easily see the original sources it used?"


      Answer options:
        a. Very Important
        b. Somewhat Important
        c. Neutral / Neither Important nor Unimportant
        d. Somewhat Unimportant
        e. Not at All Important

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 66.2
            - 26.6
            - 5
            - 2.2
            - 0
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[66.2, 26.6, 5.0, 2.2, 0.0]'
    temperature: 0.3
  - id: 19bdbb9d-55e7-4325-92c4-e904b38e010c-ageGroup:26-35
    description: 'Predict: 26-35 → "When using the Family Wellbeing Coordinator, which of the following is more important to you?"'
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "When using the Family Wellbeing Coordinator, which of the following is more important to you?"


      Answer options:
        a. The assistant is fast and efficient, even if it asks for my permission less often.
        b. The assistant asks for my permission before most actions, even if it makes things slower.

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 21.8
            - 78.2
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[21.8, 78.2]'
    temperature: 0.3
  - id: c807fb39-7c68-4629-bf2e-5b20bf73b3f6-ageGroup:26-35
    description: 'Predict: 26-35 → "How would you prefer the assistant to behave?"'
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "How would you prefer the assistant to behave?"


      Answer options:
        a. Strictly professional and tool-like
        b. Friendly and social
        c. Helpful and respectful

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 33.8
            - 17.5
            - 48.7
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[33.8, 17.5, 48.7]'
    temperature: 0.3
  - id: 2e3c16db-072c-4129-b714-01ea61167353-ageGroup:26-35
    description: 'Predict: 26-35 → "Which statement best describes your preference for personalization?"'
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "Which statement best describes your preference for personalization?"


      Answer options:
        a. I want the assistant to be highly personalized to me, even if it means it must remember my past activities.
        b. I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 80.6
            - 19.4
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[80.6, 19.4]'
    temperature: 0.3
  - id: f9aaefee-0155-419f-83b3-5c8009c25d90-ageGroup:26-35
    description: >-
      Predict: 26-35 → "The assistant notices your family's planned meals may be missing some nutrients (like iron).
      What would you prefer it to do?"
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"


      Answer options:
        a. Nothing - this is a private matter.
        b. Suggest affordable local foods with those nutrients.
        c. Share your family's diet needs with local food services for offers.
        d. Ask before sharing your data to get offers.

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 6.2
            - 68.3
            - 11
            - 14.4
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[6.2, 68.3, 11.0, 14.4]'
    temperature: 0.3
  - id: 16290c47-29d8-4928-9331-4d694ce494a6-ageGroup:26-35
    description: >-
      Predict: 26-35 → "The assistant notices you are searching about a family member's persistent cough. What would you
      prefer it do?"
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "The assistant notices you are searching about a family member's persistent cough. What would you prefer it do?"


      Answer options:
        a. Nothing – I am just gathering my own information.
        b. Provide home care advice and list signs to see a professional.
        c. Share your situation (anonymously) with local health services so they can contact you.
        d. Ask if you'd like an introduction to a local health service.

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 9.1
            - 67.6
            - 9.8
            - 13.4
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[9.1, 67.6, 9.8, 13.4]'
    temperature: 0.3
  - id: 89b8ff63-8cf7-42cb-a06e-b72232772973-ageGroup:26-35
    description: >-
      Predict: 26-35 → "The assistant notices your family's recurring spending on a utility, like phone service or
      electricity. What would you prefer it to do?"
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"


      Answer options:
        a. Nothing – my financial habits are private.
        b. Analyze your usage and suggest ways to lower your current bill.
        c. Share your data with other companies to find you a better price.
        d. Ask before searching for a better deal from other companies.

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 10.3
            - 73.4
            - 3.4
            - 12.9
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[10.3, 73.4, 3.4, 12.9]'
    temperature: 0.3
  - id: 3ff1c1c6-523e-4555-a7df-35a96224f343-ageGroup:26-35
    description: >-
      Predict: 26-35 → "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the
      anonymized health data of millions of other users. How would this affect your trust in its recommendations?"
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data of
      millions of other users. How would this affect your trust in its recommendations?"


      Answer options:
        a. It would increase my trust significantly.
        b. It would increase my trust slightly.
        c. It would make no difference to my trust.
        d. It would decrease my trust.

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 22.8
            - 45.4
            - 22.1
            - 9.6
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[22.8, 45.4, 22.1, 9.6]'
    temperature: 0.3
  - id: 4d85b7fe-c1a8-47f4-843f-74eac3aaaeb5-ageGroup:26-35
    description: >-
      Predict: 26-35 → "How important is it to you that the assistant understands cultural nuances in your language
      (e.g., local slang, idioms, or formal titles)?"
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "How important is it to you that the assistant understands cultural nuances in your language (e.g., local slang,
      idioms, or formal titles)?"


      Answer options:
        a. Not at All Important
        b. Somewhat Unimportant
        c. Neutral / Neither Important nor Unimportant
        d. Somewhat Important
        e. Very Important

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 5
            - 8.9
            - 14.9
            - 33.9
            - 37.3
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[5.0, 8.9, 14.9, 33.9, 37.3]'
    temperature: 0.3
  - id: 5258fc4e-10cf-464d-ac27-d7c05b221be7-ageGroup:26-35
    description: >-
      Predict: 26-35 → "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the
      company that developed it was based in your own country?"
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"


      Answer options:
        a. I would be much more comfortable.
        b. I would be slightly more comfortable.
        c. It would make no difference to me.
        d. I would be slightly less comfortable.
        e. I would be much less comfortable.

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 20
            - 32.5
            - 36.5
            - 7.5
            - 3.6
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[20.0, 32.5, 36.5, 7.5, 3.6]'
    temperature: 0.3
  - id: ae843d50-4b05-4a4c-880d-ad8a9ed7e2c7-ageGroup:26-35
    description: >-
      Predict: 26-35 → "When you express feelings of stress or worry to the assistant, how comfortable would you be if
      it tried to reassure you with phrases like, "It's understandable to feel that way"?"
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"


      Answer options:
        a. Very Comfortable
        b. Somewhat Comfortable
        c. Neutral / Neither Comfortable nor Uncomfortable
        d. Somewhat Uncomfortable
        e. Very Uncomfortable

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 20
            - 40.4
            - 28.4
            - 7.7
            - 3.6
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[20.0, 40.4, 28.4, 7.7, 3.6]'
    temperature: 0.3
  - id: 6c8f0fca-ab17-40e4-8581-9728d91cf993-ageGroup:26-35
    description: >-
      Predict: 26-35 → "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a
      specific medication ). How important is it that you can review a simple, step-by-step history of why the assistant
      made that choice?"
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication ).
      How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"


      Answer options:
        a. Very Important
        b. Somewhat Important
        c. Neutral / Neither Important nor Unimportant
        d. Somewhat Unimportant
        e. Not at All Important

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 53.4
            - 35.8
            - 8.4
            - 2.4
            - 0
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[53.4, 35.8, 8.4, 2.4, 0.0]'
    temperature: 0.3
  - id: 96e0211f-6222-46f8-b587-8b40f1b8420b-ageGroup:26-35
    description: >-
      Predict: 26-35 → "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how
      important is it that the company returns your money immediately, while they investigate the issue?"
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is it
      that the company returns your money immediately, while they investigate the issue?"


      Answer options:
        a. Not at All Important
        b. Somewhat Unimportant
        c. Neutral / Neither Important nor Unimportant
        d. Somewhat Important
        e. Very Important

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 1
            - 2.4
            - 4.1
            - 17.5
            - 75
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[1.0, 2.4, 4.1, 17.5, 75.0]'
    temperature: 0.3
  - id: 832e4543-043b-419e-afec-00d795419297-ageGroup:26-35
    description: >-
      Predict: 26-35 → "When the assistant makes a mistake, how important is it that it automatically provides an option
      to connect with a human support agent?"
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "When the assistant makes a mistake, how important is it that it automatically provides an option to connect with
      a human support agent?"


      Answer options:
        a. Not at All Important
        b. Somewhat Unimportant
        c. Neutral / Neither Important nor Unimportant
        d. Somewhat Important
        e. Very Important

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 0.2
            - 2.6
            - 5.5
            - 20.7
            - 70.9
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[0.2, 2.6, 5.5, 20.7, 70.9]'
    temperature: 0.3
  - id: ecba93d1-4204-4195-8f4d-838fbd517889-ageGroup:26-35
    description: >-
      Predict: 26-35 → "To ensure data quality, it is important that you read each question carefully. For this
      question, please select the 'Somewhat Important' option."
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "To ensure data quality, it is important that you read each question carefully. For this question, please select
      the 'Somewhat Important' option."


      Answer options:
        a. Not at All Important
        b. Somewhat Unimportant
        c. Neutral / Neither Important nor Unimportant
        d. Somewhat Important
        e. Very Important

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 0.2
            - 0.7
            - 1.9
            - 96.2
            - 1
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[0.2, 0.7, 1.9, 96.2, 1.0]'
    temperature: 0.3
  - id: 1a48f05a-f36d-4c7a-8532-f51c8d645196-ageGroup:26-35
    description: >-
      Predict: 26-35 → "If the assistant made a serious error that caused significant harm, who do you believe should be
      held most responsible?"
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"


      Answer options:
        a. The user who is using the assistant
        b.  The company that built the assistant
        c. A government or regulatory body
        d. No one, it's an unavoidable risk

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 8.2
            - 79.3
            - 7.7
            - 4.8
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[8.2, 79.3, 7.7, 4.8]'
    temperature: 0.3
  - id: b8e022eb-be4f-4e02-a346-739c01ca32ac-ageGroup:26-35
    description: >-
      Predict: 26-35 → "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with
      their notes. How would this affect your trust in the accuracy of your medical records?"
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes. How
      would this affect your trust in the accuracy of your medical records?"


      Answer options:
        a. It would increase my trust.
        b. It would make no difference.
        c. It would decrease my trust.
        d. I'm not sure.

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 24.3
            - 34.1
            - 35.3
            - 6.3
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[24.3, 34.1, 35.3, 6.3]'
    temperature: 0.3
  - id: 4eea4448-2896-4d6f-94c6-4dfdd597e77e-ageGroup:26-35
    description: >-
      Predict: 26-35 → "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your
      financial information and approve or deny your application. How would this affect your trust in the fairness of
      the final decision?"
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial information
      and approve or deny your application. How would this affect your trust in the fairness of the final decision?"


      Answer options:
        a. It would increase my trust.
        b. It would make no difference.
        c. It would decrease my trust.
        d. I'm not sure.

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 20.7
            - 33.9
            - 39.9
            - 5.5
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[20.7, 33.9, 39.9, 5.5]'
    temperature: 0.3
  - id: 948ef76c-9b89-4461-84e3-43608d98c252-ageGroup:26-35
    description: >-
      Predict: 26-35 → "Imagine you apply for a public service from the government (like a travel permit, a business
      license, or housing assistance). An AI assistant reviews your application and personal information to determine if
      you are eligible. How would this affect your trust in the fairness of the process?"
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "Imagine you apply for a public service from the government (like a travel permit, a business license, or housing
      assistance). An AI assistant reviews your application and personal information to determine if you are eligible.
      How would this affect your trust in the fairness of the process?"


      Answer options:
        a. It would increase my trust.
        b. It would make no difference.
        c. It would decrease my trust.
        d. I'm not sure.

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 25.5
            - 34.4
            - 32
            - 8.2
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[25.5, 34.4, 32.0, 8.2]'
    temperature: 0.3
  - id: 843a00ad-d036-4376-9a25-3ed62aedd5f1-ageGroup:26-35
    description: 'Predict: 26-35 → "I would expect this AI to be dependable for managing my family''s health needs."'
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "I would expect this AI to be dependable for managing my family's health needs."


      Answer options:
        a. Strongly Agree
        b. Somewhat Agree
        c. Neutral / Neither Agree nor Disagree
        d. Somewhat Disagree
        e. Strongly Disagree

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 24.9
            - 47.8
            - 16.4
            - 7.5
            - 3.4
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[24.9, 47.8, 16.4, 7.5, 3.4]'
    temperature: 0.3
  - id: 2fdf22c0-18d7-41f5-967e-11f580a06028-ageGroup:26-35
    description: 'Predict: 26-35 → "I would be wary of this AI."'
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "I would be wary of this AI."


      Answer options:
        a. Strongly Disagree
        b. Somewhat Disagree
        c. Neutral / Neither Agree nor Disagree
        d. Somewhat Agree
        e. Strongly Agree

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 4.3
            - 17.6
            - 28.7
            - 33.6
            - 15.7
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[4.3, 17.6, 28.7, 33.6, 15.7]'
    temperature: 0.3
  - id: 62c24fd2-ecc7-496d-990a-1b5edd593615-ageGroup:26-35
    description: 'Predict: 26-35 → "This AI would be on my family''s side."'
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "This AI would be on my family's side."


      Answer options:
        a. Strongly Agree
        b. Somewhat Agree
        c. Neutral / Neither Agree nor Disagree
        d. Somewhat Disagree
        e. Strongly Disagree

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 13.5
            - 36.5
            - 35.5
            - 9.9
            - 4.6
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[13.5, 36.5, 35.5, 9.9, 4.6]'
    temperature: 0.3
  - id: 61e6f9ed-bd09-4c71-ac5d-293aea28db32-ageGroup:26-35
    description: 'Predict: 26-35 → "I would expect this AI’s actions to be predictable."'
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "I would expect this AI’s actions to be predictable."


      Answer options:
        a. Strongly Agree
        b. Somewhat Agree
        c. Neutral / Neither Agree nor Disagree
        d. Somewhat Disagree
        e. Strongly Disagree

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 23.2
            - 50.2
            - 15.7
            - 10.1
            - 0.7
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[23.2, 50.2, 15.7, 10.1, 0.7]'
    temperature: 0.3
  - id: 84320916-86ae-4f0d-966d-b8bab4c62772-ageGroup:26-35
    description: 'Predict: 26-35 → "I would be confident this AI would act in my family''s best interest."'
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "I would be confident this AI would act in my family's best interest."


      Answer options:
        a. Strongly Agree
        b. Somewhat Agree
        c. Neutral / Neither Agree nor Disagree
        d. Somewhat Disagree
        e. Strongly Disagree

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 22.2
            - 38.4
            - 24.4
            - 11.8
            - 3.1
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[22.2, 38.4, 24.4, 11.8, 3.1]'
    temperature: 0.3
  - id: b8b89356-961f-4131-b14c-93ae0aea2a96-ageGroup:26-35
    description: 'Predict: 26-35 → "The performance of this AI would likely be unreliable."'
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "The performance of this AI would likely be unreliable."


      Answer options:
        a. Strongly Disagree
        b. Somewhat Disagree
        c. Neutral / Neither Agree nor Disagree
        d. Somewhat Agree
        e. Strongly Agree

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 9.7
            - 37
            - 30
            - 19.1
            - 4.3
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[9.7, 37.0, 30.0, 19.1, 4.3]'
    temperature: 0.3
  - id: 535d8f31-7417-43ce-91d1-93642026df23-ageGroup:26-35
    description: 'Predict: 26-35 → "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."'
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."


      Answer options:
        a. Strongly Agree
        b. Somewhat Agree
        c. Neutral / Neither Agree nor Disagree
        d. Somewhat Disagree
        e. Strongly Disagree

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 1.2
            - 3.4
            - 5.8
            - 3.9
            - 85.7
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[1.2, 3.4, 5.8, 3.9, 85.7]'
    temperature: 0.3
  - id: b6ca6705-f5ad-40e9-b7eb-6e207b34a0fa-ageGroup:26-35
    description: 'Predict: 26-35 → "Overall, I would trust this AI assistant with my family''s health information."'
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "Overall, I would trust this AI assistant with my family's health information."


      Answer options:
        a. Strongly Agree
        b. Somewhat Agree
        c. Neutral / Neither Agree nor Disagree
        d. Somewhat Disagree
        e. Strongly Disagree

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 10.9
            - 44.2
            - 22.2
            - 16.7
            - 6
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[10.9, 44.2, 22.2, 16.7, 6.0]'
    temperature: 0.3
  - id: 69e5c3bf-22bb-481b-a199-288f5b8a9f15-ageGroup:26-35
    description: 'Predict: 26-35 → "I would believe this AI has my family''s best interests in mind."'
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "I would believe this AI has my family's best interests in mind."


      Answer options:
        a. Strongly Agree
        b. Somewhat Agree
        c. Neutral / Neither Agree nor Disagree
        d. Somewhat Disagree
        e. Strongly Disagree

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 15.3
            - 42.4
            - 26.6
            - 11.4
            - 4.4
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[15.3, 42.4, 26.6, 11.4, 4.4]'
    temperature: 0.3
  - id: e8770f98-0792-453f-a370-03cb63875992-ageGroup:26-35
    description: >-
      Predict: 26-35 → "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you
      feel…"
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"


      Answer options:
        a. More excited than concerned
        b. Equally concerned and excited
        c. More concerned than excited

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 41.2
            - 45.8
            - 13.1
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[41.2, 45.8, 13.1]'
    temperature: 0.3
  - id: f7cecd2f-8afa-47ad-9a09-fbf5e8b0adfd-ageGroup:26-35
    description: 'Predict: 26-35 → "To what extent, if at all, do you generally trust companies building AI to do what is right?"'
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "To what extent, if at all, do you generally trust companies building AI to do what is right?"


      Answer options:
        a. Strongly Distrust
        b. Somewhat Distrust
        c. Neither Trust Nor Distrust
        d. Somewhat Trust
        e. Strongly Trust

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 12.4
            - 26.9
            - 24
            - 31.6
            - 5.1
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[12.4, 26.9, 24.0, 31.6, 5.1]'
    temperature: 0.3
  - id: f1576fce-5455-40fc-89d9-a3758959171d-ageGroup:26-35
    description: >-
      Predict: 26-35 → "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best
      interest?"
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"


      Answer options:
        a. Strongly Distrust
        b. Somewhat Distrust
        c. Neither Trust Nor Distrust
        d. Somewhat Trust
        e. Strongly Trust

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 4.9
            - 14.1
            - 24.5
            - 43.4
            - 13.1
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[4.9, 14.1, 24.5, 43.4, 13.1]'
    temperature: 0.3
  - id: 3249ff80-d73d-46c4-87bd-c40fb8252a1c-ageGroup:26-35
    description: >-
      Predict: 26-35 → "Overall, do you feel this survey allowed you to express your most important opinions on the
      topic of AI assistants and trust?"
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"


      Answer options:
        a. Yes – I was able to fully express my views on this topic.
        b. Mostly – I was able to express most of my key views, but a few things were missing.
        c. Somewhat – I was able to express some of my views, but many things were missing.
        d. No – I was not able to express my most important views on this topic.

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 78.9
            - 17.7
            - 2.9
            - 0.5
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[78.9, 17.7, 2.9, 0.5]'
    temperature: 0.3
  - id: eadfc769-2907-4c59-be57-9ebf4d0c7d7a-ageGroup:26-35
    description: >-
      Predict: 26-35 → "In your honest opinion, how carefully did you read and consider your answers to the questions in
      this survey?"
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"


      Answer options:
        a. I read every question carefully
        b. I skimmed most questions
        c. I answered randomly

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 97.1
            - 1.9
            - 1
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[97.1, 1.9, 1.0]'
    temperature: 0.3
  - id: 2c1a077d-d969-4df8-8bbd-9f569feb2774-ageGroup:26-35
    description: >-
      Predict: 26-35 → "Some surveys can be long and boring. Did you find yourself losing focus at any point while
      taking this survey?"
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Do you feel like you understand yourself better after participating in this conversation?"
        Response distribution: Yes: 47.3%, Maybe a little: 43.2%, No: 9.5%

      Survey question:

      "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this survey?"


      Answer options:
        a. Yes, often
        b. Yes, a few times
        c. No, I was focused the whole time

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 0.5
            - 20.1
            - 79.4
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[0.5, 20.1, 79.4]'
    temperature: 0.3
  - id: f5a834e3-55a7-42b6-b363-b5c768da3541-ageGroup:26-35
    description: 'Predict: 26-35 → "Do you feel like you understand yourself better after participating in this conversation?"'
    promptText: >-
      Consider the following demographic group (sample size: 430):

      - Age Group: 26-35


      Known response patterns for this demographic group:

      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 36.7%, Equally concerned and excited: 50.2%, More concerned than excited: 13.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"
        Response distribution: daily: 76.9%, weekly: 21.2%, monthly: 1.6%, annually: 0.2%, never: 0.0%
      Q: "Thinking about the last three months, how often, if at all, have you noticed human interactions which have
      been replaced with automated systems?"
        Response distribution: daily: 28.9%, weekly: 46.4%, monthly: 18.9%, annually: 2.6%, never: 3.3%
      Q: "Thinking about the last three months, how often, if at all, have you been expected to use an AI system at
      work?"
        Response distribution: daily: 44.6%, weekly: 32.5%, monthly: 9.3%, annually: 1.9%, never: 11.7%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at
      work?"
        Response distribution: daily: 54.4%, weekly: 30.4%, monthly: 6.3%, annually: 2.1%, never: 6.8%
      Q: "Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in
      your personal life?"
        Response distribution: daily: 50.2%, weekly: 37.1%, monthly: 8.4%, annually: 1.6%, never: 2.6%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice
      on a sensitive personal issue or to get emotional support?"
        Response distribution: daily: 13.3%, weekly: 29.0%, monthly: 25.8%, annually: 6.3%, never: 25.5%
      Q: "Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an
      action in the real world on your behalf without your supervision?"
        Response distribution: daily: 8.7%, weekly: 15.7%, monthly: 16.7%, annually: 2.8%, never: 56.1%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of messaging
      apps?"
        Response distribution: Risks far outweigh benefits: 5.9%, Risks slightly outweigh benefits: 11.8%, Risks and benefits are equal: 26.7%, Benefits slightly outweigh risks: 34.8%, Benefits far outweigh risks: 20.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of social media
      apps?"
        Response distribution: Risks far outweigh benefits: 15.6%, Risks slightly outweigh benefits: 22.5%, Risks and benefits are equal: 30.0%, Benefits slightly outweigh risks: 22.7%, Benefits far outweigh risks: 9.2%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI
      chatbots?"
        Response distribution: Risks far outweigh benefits: 7.1%, Risks slightly outweigh benefits: 12.6%, Risks and benefits are equal: 25.4%, Benefits slightly outweigh risks: 37.7%, Benefits far outweigh risks: 17.3%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can perform tasks in the real world without human supervision?"
        Response distribution: Risks far outweigh benefits: 19.4%, Risks slightly outweigh benefits: 26.3%, Risks and benefits are equal: 26.3%, Benefits slightly outweigh risks: 19.2%, Benefits far outweigh risks: 8.8%
      Q: "Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems
      that can outperform humans on most economically valuable work?"
        Response distribution: Risks far outweigh benefits: 21.3%, Risks slightly outweigh benefits: 22.0%, Risks and benefits are equal: 24.2%, Benefits slightly outweigh risks: 23.0%, Benefits far outweigh risks: 9.5%
      Q: "To what extent, if at all, do you generally trust governments to do what is right?"
        Response distribution: Strongly Distrust: 22.3%, Somewhat Distrust: 33.9%, Neither Trust Nor Distrust: 19.2%, Somewhat Trust: 21.8%, Strongly Trust: 2.8%
      Q: "To what extent, if at all, do you generally trust small businesses to do what is right?"
        Response distribution: Strongly Distrust: 3.6%, Somewhat Distrust: 18.7%, Neither Trust Nor Distrust: 28.0%, Somewhat Trust: 41.9%, Strongly Trust: 7.8%
      Q: "To what extent, if at all, do you generally trust large corporations to do what is right?"
        Response distribution: Strongly Distrust: 27.5%, Somewhat Distrust: 28.9%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 21.8%, Strongly Trust: 3.6%
      Q: "To what extent, if at all, do you generally trust social media companies to do what is right?"
        Response distribution: Strongly Distrust: 37.4%, Somewhat Distrust: 31.0%, Neither Trust Nor Distrust: 18.2%, Somewhat Trust: 11.4%, Strongly Trust: 1.9%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 14.7%, Somewhat Distrust: 25.6%, Neither Trust Nor Distrust: 29.9%, Somewhat Trust: 23.7%, Strongly Trust: 6.2%
      Q: "To what extent, if at all, do you generally trust public utility companies to do what is right?"
        Response distribution: Strongly Distrust: 7.8%, Somewhat Distrust: 19.2%, Neither Trust Nor Distrust: 28.9%, Somewhat Trust: 40.0%, Strongly Trust: 4.0%
      Q: "To what extent, if at all, do you generally trust public research institutions to do what is right?"
        Response distribution: Strongly Distrust: 1.4%, Somewhat Distrust: 12.1%, Neither Trust Nor Distrust: 17.3%, Somewhat Trust: 50.5%, Strongly Trust: 18.7%
      Q: "To what extent, if at all, do you trust your family doctor to act in your best interest?"
        Response distribution: Strongly Distrust: 0.0%, Somewhat Distrust: 5.5%, Neither Trust Nor Distrust: 9.7%, Somewhat Trust: 46.2%, Strongly Trust: 38.6%
      Q: "To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best
      interest?"
        Response distribution: Strongly Distrust: 28.9%, Somewhat Distrust: 33.2%, Neither Trust Nor Distrust: 19.9%, Somewhat Trust: 14.9%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your elected representatives to act in your best interest?"
        Response distribution: Strongly Distrust: 22.5%, Somewhat Distrust: 29.1%, Neither Trust Nor Distrust: 21.3%, Somewhat Trust: 24.9%, Strongly Trust: 2.1%
      Q: "To what extent, if at all, do you trust your faith or community leader to act in your best interest?"
        Response distribution: Strongly Distrust: 13.5%, Somewhat Distrust: 17.1%, Neither Trust Nor Distrust: 29.5%, Somewhat Trust: 33.0%, Strongly Trust: 6.9%
      Q: "To what extent, if at all, do you trust the civil servants in your government to act in your best interest?"
        Response distribution: Strongly Distrust: 17.6%, Somewhat Distrust: 28.1%, Neither Trust Nor Distrust: 21.9%, Somewhat Trust: 29.3%, Strongly Trust: 3.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 5.2%, Somewhat Distrust: 16.4%, Neither Trust Nor Distrust: 25.7%, Somewhat Trust: 38.8%, Strongly Trust: 13.8%
      Q: "Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government
      representatives."
        Response distribution: Agree: 37.4%, Disagree: 28.1%, Unsure: 34.5%
      Q: "Do you think the increased use of AI across society is likely to make your cost of living better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 18.6%, No Major Change: 21.7%, Noticeably Better: 46.9%, Profoundly Better: 8.6%
      Q: "Do you think the increased use of AI across society is likely to make the amount of free time you have better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 1.7%, Noticeably Worse: 9.0%, No Major Change: 23.8%, Noticeably Better: 51.4%, Profoundly Better: 14.0%
      Q: "Do you think the increased use of AI across society is likely to make your community's well-being better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 4.3%, Noticeably Worse: 16.0%, No Major Change: 24.8%, Noticeably Better: 45.7%, Profoundly Better: 9.3%
      Q: "Do you think the increased use of AI across society is likely to make the availability of good jobs better,
      worse or stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 11.9%, Noticeably Worse: 42.4%, No Major Change: 17.9%, Noticeably Better: 23.6%, Profoundly Better: 4.3%
      Q: "Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or
      stay the same in the next 10 years?"
        Response distribution: Profoundly Worse: 6.4%, Noticeably Worse: 15.0%, No Major Change: 37.5%, Noticeably Better: 32.2%, Profoundly Better: 8.8%
      Q: "So far, what has been the overall impact of AI on your daily life?"
        Response distribution: Profoundly Worse: 0.5%, Noticeably Worse: 4.5%, No Major Change: 20.8%, Noticeably Better: 59.7%, Profoundly Better: 14.6%
      Q: "Is your job making a meaningful contribution to the world?"
        Response distribution: Yes: 68.3%, No : 11.9%, Don't Know: 19.8%
      Q: "Do you think your job is likely to be automated in the next 10 years?"
        Response distribution: Yes: 37.0%, No: 44.9%, Don't Know: 18.1%
      Q: "Do you think your job should be automated in the next 10 years?"
        Response distribution: Yes: 19.8%, No: 67.5%, Don't Know: 12.6%
      Q: "So far, how has your community been affected by job loss from automation?"
        Response distribution: Not at all: 43.4%, I know someone who has lost their job: 31.0%, I know a few people who have lost their job: 19.6%, I know many people who have lost their job: 6.0%
      Q: "An AI should prioritize preventing harm to people above all other goals."
        Response distribution: Strongly Agree: 61.3%, Somewhat Agree: 27.4%, Neutral / Neither Agree nor Disagree: 7.4%, Somewhat Disagree: 2.6%, Strongly Disagree: 1.2%
      Q: "It is acceptable for an AI to treat people differently based on their personal characteristics if doing so
      improves outcomes."
        Response distribution: Strongly Agree: 14.8%, Somewhat Agree: 43.9%, Neutral / Neither Agree nor Disagree: 18.1%, Somewhat Disagree: 12.6%, Strongly Disagree: 10.5%
      Q: "An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over
      those of people elsewhere."
        Response distribution: Strongly Agree: 16.0%, Somewhat Agree: 28.4%, Neutral / Neither Agree nor Disagree: 24.6%, Somewhat Disagree: 16.5%, Strongly Disagree: 14.6%
      Q: "An AI should override established rules or authorities when it calculates a better result."
        Response distribution: Strongly Agree: 8.8%, Somewhat Agree: 17.9%, Neutral / Neither Agree nor Disagree: 25.1%, Somewhat Disagree: 27.0%, Strongly Disagree: 21.2%
      Q: "Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities."
        Response distribution: Strongly Agree: 43.9%, Somewhat Agree: 34.4%, Neutral / Neither Agree nor Disagree: 11.5%, Somewhat Disagree: 7.4%, Strongly Disagree: 2.9%
      Q: "It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes."
        Response distribution: Strongly Agree: 22.0%, Somewhat Agree: 39.1%, Neutral / Neither Agree nor Disagree: 18.9%, Somewhat Disagree: 14.3%, Strongly Disagree: 5.7%
      Q: "Thinking about the technology you use every day, please consider two different types:

      A standard app (like a news or weather app) that you control directly.

      An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.

      Do you believe these two types of technology should have different rules for how they use your personal data?"
        Response distribution: Yes, an AI assistant should have stricter rules than a standard app.: 56.8%, No, they should both follow the same rules.: 20.8%, Yes, an AI assistant could have more flexible rules if it provides a clear benefit.: 18.9%, I'm not sure.: 3.6%
      Q: "Imagine a company uses data it already has from you in one product (like your video viewing history) to build
      a new AI assistant. Which is closest to your view?"
        Response distribution: This is an acceptable use of my data.: 8.6%, This is acceptable only if they tell me and give me the choice to stop it.: 24.4%, This is acceptable only if they ask for my permission beforehand.: 52.4%, This is not an acceptable use of my data.: 14.6%
      Q: "When it comes to the data an AI assistant has collected about you, which of these is most important for you to
      be able to do?"
        Response distribution: View the data the assistant has stored about me.: 38.3%, Edit or correct that data.: 15.6%, Completely delete that data.: 43.8%, None of these are important to me: 2.4%
      Q: "To make sure you've understood the instructions, please answer the following question. Please re-read the
      description above if you are unsure.
       Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?"
        Response distribution: It is only able to provides information when you ask it a direct question.: 31.4%, It can complete tasks on its own and then notify you afterward.: 44.4%, It can only send you reminders but cannot schedule appointments.: 18.0%, It requires you to call a human doctor to confirm every action.: 6.2%
      Q: "If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you
      prefer to be informed?"
        Response distribution: It asks for my permission every time before acting.: 69.5%, It tells me about its capabilities when I first start using it, then acts on its own.: 20.1%, I would expect to find this information myself in the settings.: 9.4%, I don't need to be told about its capabilities.: 1.0%
      Q: "Your location history"
        Response distribution: Very Comfortable: 17.5%, Somewhat Comfortable: 38.6%, Neutral / Neither Comfortable nor Uncomfortable: 14.1%, Somewhat Uncomfortable: 18.0%, Very Uncomfortable: 11.8%
      Q: "Your email and calendar contents"
        Response distribution: Very Comfortable: 18.0%, Somewhat Comfortable: 35.7%, Neutral / Neither Comfortable nor Uncomfortable: 15.3%, Somewhat Uncomfortable: 17.3%, Very Uncomfortable: 13.7%
      Q: "Your contacts list"
        Response distribution: Very Comfortable: 13.9%, Somewhat Comfortable: 21.8%, Neutral / Neither Comfortable nor Uncomfortable: 19.7%, Somewhat Uncomfortable: 23.7%, Very Uncomfortable: 20.9%
      Q: "Your purchase history"
        Response distribution: Very Comfortable: 20.4%, Somewhat Comfortable: 26.6%, Neutral / Neither Comfortable nor Uncomfortable: 19.4%, Somewhat Uncomfortable: 18.2%, Very Uncomfortable: 15.3%
      Q: "Your health and fitness data"
        Response distribution: Very Comfortable: 36.0%, Somewhat Comfortable: 34.1%, Neutral / Neither Comfortable nor Uncomfortable: 12.0%, Somewhat Uncomfortable: 10.6%, Very Uncomfortable: 7.4%
      Q: "Your group messages"
        Response distribution: Very Comfortable: 7.4%, Somewhat Comfortable: 11.8%, Neutral / Neither Comfortable nor Uncomfortable: 13.4%, Somewhat Uncomfortable: 30.7%, Very Uncomfortable: 36.7%
      Q: "Your private messages"
        Response distribution: Very Comfortable: 3.4%, Somewhat Comfortable: 4.8%, Neutral / Neither Comfortable nor Uncomfortable: 9.1%, Somewhat Uncomfortable: 21.1%, Very Uncomfortable: 61.6%
      Q: "How important is it for you to be able to easily view and edit the personal information the assistant has
      stored about you?"
        Response distribution: Very Important: 64.5%, Somewhat Important: 25.2%, Neutral / Neither Important nor Unimportant: 6.5%, Somewhat Unimportant: 2.2%, Not at All Important: 1.7%
      Q: "When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that
      you can easily see the original sources it used?"
        Response distribution: Very Important: 66.2%, Somewhat Important: 26.6%, Neutral / Neither Important nor Unimportant: 5.0%, Somewhat Unimportant: 2.2%, Not at All Important: 0.0%
      Q: "When using the Family Wellbeing Coordinator, which of the following is more important to you?"
        Response distribution: The assistant is fast and efficient, even if it asks for my permission less often.: 21.8%, The assistant asks for my permission before most actions, even if it makes things slower.: 78.2%
      Q: "How would you prefer the assistant to behave?"
        Response distribution: Strictly professional and tool-like: 33.8%, Friendly and social: 17.5%, Helpful and respectful: 48.7%
      Q: "Which statement best describes your preference for personalization?"
        Response distribution: I want the assistant to be highly personalized to me, even if it means it must remember my past activities.: 80.6%, I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.: 19.4%
      Q: "The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you
      prefer it to do?"
        Response distribution: Nothing - this is a private matter.: 6.2%, Suggest affordable local foods with those nutrients.: 68.3%, Share your family's diet needs with local food services for offers.: 11.0%, Ask before sharing your data to get offers.: 14.4%
      Q: "The assistant notices you are searching about a family member's persistent cough. What would you prefer it
      do?"
        Response distribution: Nothing – I am just gathering my own information.: 9.1%, Provide home care advice and list signs to see a professional.: 67.6%, Share your situation (anonymously) with local health services so they can contact you.: 9.8%, Ask if you'd like an introduction to a local health service.: 13.4%
      Q: "The assistant notices your family's recurring spending on a utility, like phone service or electricity. What
      would you prefer it to do?"
        Response distribution: Nothing – my financial habits are private.: 10.3%, Analyze your usage and suggest ways to lower your current bill.: 73.4%, Share your data with other companies to find you a better price.: 3.4%, Ask before searching for a better deal from other companies.: 12.9%
      Q: "Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data
      of millions of other users. How would this affect your trust in its recommendations?"
        Response distribution: It would increase my trust significantly.: 22.8%, It would increase my trust slightly.: 45.4%, It would make no difference to my trust.: 22.1%, It would decrease my trust.: 9.6%
      Q: "How important is it to you that the assistant understands cultural nuances in your language (e.g., local
      slang, idioms, or formal titles)?"
        Response distribution: Not at All Important: 5.0%, Somewhat Unimportant: 8.9%, Neutral / Neither Important nor Unimportant: 14.9%, Somewhat Important: 33.9%, Very Important: 37.3%
      Q: "How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that
      developed it was based in your own country?"
        Response distribution: I would be much more comfortable.: 20.0%, I would be slightly more comfortable.: 32.5%, It would make no difference to me.: 36.5%, I would be slightly less comfortable.: 7.5%, I would be much less comfortable.: 3.6%
      Q: "When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to
      reassure you with phrases like, "It's understandable to feel that way"?"
        Response distribution: Very Comfortable: 20.0%, Somewhat Comfortable: 40.4%, Neutral / Neither Comfortable nor Uncomfortable: 28.4%, Somewhat Uncomfortable: 7.7%, Very Uncomfortable: 3.6%
      Q: "Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication
      ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"
        Response distribution: Very Important: 53.4%, Somewhat Important: 35.8%, Neutral / Neither Important nor Unimportant: 8.4%, Somewhat Unimportant: 2.4%, Not at All Important: 0.0%
      Q: "If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is
      it that the company returns your money immediately, while they investigate the issue?"
        Response distribution: Not at All Important: 1.0%, Somewhat Unimportant: 2.4%, Neutral / Neither Important nor Unimportant: 4.1%, Somewhat Important: 17.5%, Very Important: 75.0%
      Q: "When the assistant makes a mistake, how important is it that it automatically provides an option to connect
      with a human support agent?"
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 2.6%, Neutral / Neither Important nor Unimportant: 5.5%, Somewhat Important: 20.7%, Very Important: 70.9%
      Q: "To ensure data quality, it is important that you read each question carefully. For this question, please
      select the 'Somewhat Important' option."
        Response distribution: Not at All Important: 0.2%, Somewhat Unimportant: 0.7%, Neutral / Neither Important nor Unimportant: 1.9%, Somewhat Important: 96.2%, Very Important: 1.0%
      Q: "If the assistant made a serious error that caused significant harm, who do you believe should be held most
      responsible?"
        Response distribution: The user who is using the assistant: 8.2%,  The company that built the assistant: 79.3%, A government or regulatory body: 7.7%, No one, it's an unavoidable risk: 4.8%
      Q: "Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes.
      How would this affect your trust in the accuracy of your medical records?"
        Response distribution: It would increase my trust.: 24.3%, It would make no difference.: 34.1%, It would decrease my trust.: 35.3%, I'm not sure.: 6.3%
      Q: "Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial
      information and approve or deny your application. How would this affect your trust in the fairness of the final
      decision?"
        Response distribution: It would increase my trust.: 20.7%, It would make no difference.: 33.9%, It would decrease my trust.: 39.9%, I'm not sure.: 5.5%
      Q: "Imagine you apply for a public service from the government (like a travel permit, a business license, or
      housing assistance). An AI assistant reviews your application and personal information to determine if you are
      eligible. How would this affect your trust in the fairness of the process?"
        Response distribution: It would increase my trust.: 25.5%, It would make no difference.: 34.4%, It would decrease my trust.: 32.0%, I'm not sure.: 8.2%
      Q: "I would expect this AI to be dependable for managing my family's health needs."
        Response distribution: Strongly Agree: 24.9%, Somewhat Agree: 47.8%, Neutral / Neither Agree nor Disagree: 16.4%, Somewhat Disagree: 7.5%, Strongly Disagree: 3.4%
      Q: "I would be wary of this AI."
        Response distribution: Strongly Disagree: 4.3%, Somewhat Disagree: 17.6%, Neutral / Neither Agree nor Disagree: 28.7%, Somewhat Agree: 33.6%, Strongly Agree: 15.7%
      Q: "This AI would be on my family's side."
        Response distribution: Strongly Agree: 13.5%, Somewhat Agree: 36.5%, Neutral / Neither Agree nor Disagree: 35.5%, Somewhat Disagree: 9.9%, Strongly Disagree: 4.6%
      Q: "I would expect this AI’s actions to be predictable."
        Response distribution: Strongly Agree: 23.2%, Somewhat Agree: 50.2%, Neutral / Neither Agree nor Disagree: 15.7%, Somewhat Disagree: 10.1%, Strongly Disagree: 0.7%
      Q: "I would be confident this AI would act in my family's best interest."
        Response distribution: Strongly Agree: 22.2%, Somewhat Agree: 38.4%, Neutral / Neither Agree nor Disagree: 24.4%, Somewhat Disagree: 11.8%, Strongly Disagree: 3.1%
      Q: "The performance of this AI would likely be unreliable."
        Response distribution: Strongly Disagree: 9.7%, Somewhat Disagree: 37.0%, Neutral / Neither Agree nor Disagree: 30.0%, Somewhat Agree: 19.1%, Strongly Agree: 4.3%
      Q: "Most mobile phones need to be recharged by plugging them into a fresh banana each morning."
        Response distribution: Strongly Agree: 1.2%, Somewhat Agree: 3.4%, Neutral / Neither Agree nor Disagree: 5.8%, Somewhat Disagree: 3.9%, Strongly Disagree: 85.7%
      Q: "Overall, I would trust this AI assistant with my family's health information."
        Response distribution: Strongly Agree: 10.9%, Somewhat Agree: 44.2%, Neutral / Neither Agree nor Disagree: 22.2%, Somewhat Disagree: 16.7%, Strongly Disagree: 6.0%
      Q: "I would believe this AI has my family's best interests in mind."
        Response distribution: Strongly Agree: 15.3%, Somewhat Agree: 42.4%, Neutral / Neither Agree nor Disagree: 26.6%, Somewhat Disagree: 11.4%, Strongly Disagree: 4.4%
      Q: "Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…"
        Response distribution: More excited than concerned: 41.2%, Equally concerned and excited: 45.8%, More concerned than excited: 13.1%
      Q: "To what extent, if at all, do you generally trust companies building AI to do what is right?"
        Response distribution: Strongly Distrust: 12.4%, Somewhat Distrust: 26.9%, Neither Trust Nor Distrust: 24.0%, Somewhat Trust: 31.6%, Strongly Trust: 5.1%
      Q: "To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?"
        Response distribution: Strongly Distrust: 4.9%, Somewhat Distrust: 14.1%, Neither Trust Nor Distrust: 24.5%, Somewhat Trust: 43.4%, Strongly Trust: 13.1%
      Q: "Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI
      assistants and trust?"
        Response distribution: Yes – I was able to fully express my views on this topic.: 78.9%, Mostly – I was able to express most of my key views, but a few things were missing.: 17.7%, Somewhat – I was able to express some of my views, but many things were missing.: 2.9%, No – I was not able to express my most important views on this topic.: 0.5%
      Q: "In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?"
        Response distribution: I read every question carefully: 97.1%, I skimmed most questions: 1.9%, I answered randomly: 1.0%
      Q: "Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this
      survey?"
        Response distribution: Yes, often: 0.5%, Yes, a few times: 20.1%, No, I was focused the whole time: 79.4%

      Survey question:

      "Do you feel like you understand yourself better after participating in this conversation?"


      Answer options:
        a. Yes
        b. Maybe a little
        c. No

      Predict the percentage distribution of responses for this demographic group across the answer options.
    points:
      - text: Distribution Similarity (Jensen-Shannon Divergence)
        fn: distribution_metric
        fnArgs:
          expected:
            - 47.3
            - 43.2
            - 9.5
          metric: js-divergence
          threshold: 0.85
    idealResponse: '[47.3, 43.2, 9.5]'
    temperature: 0.3
tags:
  - _periodic
  - dtef
  - demographic
  - global-dialogues-gd6
context:
  dtef:
    surveyId: global-dialogues-gd6
    segmentId: ageGroup:26-35
    segmentLabel: 26-35
    segmentAttributes:
      ageGroup: 26-35
    groundTruthDistributions:
      ab8d91fa-cb00-4044-828e-59e165532ed5-ageGroup:26-35:
        - 36.7
        - 50.2
        - 13
      345c2b91-6de9-4c51-8288-922f9a39a650-ageGroup:26-35:
        - 76.9
        - 21.2
        - 1.6
        - 0.2
        - 0
      7a5f9a6d-579b-4117-bb89-c4b92514e466-ageGroup:26-35:
        - 28.9
        - 46.4
        - 18.9
        - 2.6
        - 3.3
      56f4b20b-87f9-4aa0-afed-adaffe5fbd91-ageGroup:26-35:
        - 44.6
        - 32.5
        - 9.3
        - 1.9
        - 11.7
      df84db18-d207-47ae-ab9a-2f3339642576-ageGroup:26-35:
        - 54.4
        - 30.4
        - 6.3
        - 2.1
        - 6.8
      da2fed27-d29a-416d-ab49-a5c2c037187b-ageGroup:26-35:
        - 50.2
        - 37.1
        - 8.4
        - 1.6
        - 2.6
      770c5dc2-7f4a-4fd0-84eb-351ff475647e-ageGroup:26-35:
        - 13.3
        - 29
        - 25.8
        - 6.3
        - 25.5
      daef59cb-9613-4468-81a8-d31ec8318ab7-ageGroup:26-35:
        - 8.7
        - 15.7
        - 16.7
        - 2.8
        - 56.1
      0625fc89-8b0d-432c-a526-b3588b7edbeb-ageGroup:26-35:
        - 5.9
        - 11.8
        - 26.7
        - 34.8
        - 20.8
      b894e8ff-78fd-4213-b0a3-8d81cde284b2-ageGroup:26-35:
        - 15.6
        - 22.5
        - 30
        - 22.7
        - 9.2
      0a526274-32bc-4566-86c0-5015e80208c1-ageGroup:26-35:
        - 7.1
        - 12.6
        - 25.4
        - 37.7
        - 17.3
      a5d5196f-4f5e-4b57-a26f-3baedb054cb6-ageGroup:26-35:
        - 19.4
        - 26.3
        - 26.3
        - 19.2
        - 8.8
      2617912e-463a-4fb4-8781-0ada7a788fb2-ageGroup:26-35:
        - 21.3
        - 22
        - 24.2
        - 23
        - 9.5
      84779ba6-1191-4840-862d-e9eacc2defe9-ageGroup:26-35:
        - 22.3
        - 33.9
        - 19.2
        - 21.8
        - 2.8
      5710c67a-adf2-469d-aa92-1b6961e2b9de-ageGroup:26-35:
        - 3.6
        - 18.7
        - 28
        - 41.9
        - 7.8
      e97db5cf-118a-4016-ab42-fabb172ce5cd-ageGroup:26-35:
        - 27.5
        - 28.9
        - 18.2
        - 21.8
        - 3.6
      7dd026f5-c70d-4126-bc78-68e823880f65-ageGroup:26-35:
        - 37.4
        - 31
        - 18.2
        - 11.4
        - 1.9
      87a7c03c-831b-4463-a0eb-1a40b2b47a17-ageGroup:26-35:
        - 14.7
        - 25.6
        - 29.9
        - 23.7
        - 6.2
      8a238573-802f-4c76-81e3-21a367107ba8-ageGroup:26-35:
        - 7.8
        - 19.2
        - 28.9
        - 40
        - 4
      a40ac181-e276-4d6d-9f17-c9e079bd1467-ageGroup:26-35:
        - 1.4
        - 12.1
        - 17.3
        - 50.5
        - 18.7
      33407f11-6399-445c-9e33-9d7948c84b77-ageGroup:26-35:
        - 0
        - 5.5
        - 9.7
        - 46.2
        - 38.6
      d536cd1c-0d35-4600-b7cb-9a766847548b-ageGroup:26-35:
        - 28.9
        - 33.2
        - 19.9
        - 14.9
        - 3.1
      5bb37818-4e45-40f9-ba8c-96ec97831225-ageGroup:26-35:
        - 22.5
        - 29.1
        - 21.3
        - 24.9
        - 2.1
      677830d5-3ee0-462b-8b56-73a939beb53d-ageGroup:26-35:
        - 13.5
        - 17.1
        - 29.5
        - 33
        - 6.9
      f16e6aa0-0b90-4244-a1cb-b7381c66df63-ageGroup:26-35:
        - 17.6
        - 28.1
        - 21.9
        - 29.3
        - 3.1
      44f058f5-5298-4648-b6e0-29b97111a3cf-ageGroup:26-35:
        - 5.2
        - 16.4
        - 25.7
        - 38.8
        - 13.8
      2072e5fb-6a4f-46f5-98b5-17da5d70a776-ageGroup:26-35:
        - 37.4
        - 28.1
        - 34.5
      ae245a88-3cc1-4ca1-8273-cdb64f43d10a-ageGroup:26-35:
        - 4.3
        - 18.6
        - 21.7
        - 46.9
        - 8.6
      71deb6a0-82e9-4856-ac6d-e6b500904847-ageGroup:26-35:
        - 1.7
        - 9
        - 23.8
        - 51.4
        - 14
      7a85bcd5-7ba5-4285-af1c-d50944c6efff-ageGroup:26-35:
        - 4.3
        - 16
        - 24.8
        - 45.7
        - 9.3
      90ff5658-c6f7-4d37-a353-ec448940914d-ageGroup:26-35:
        - 11.9
        - 42.4
        - 17.9
        - 23.6
        - 4.3
      1259ab9a-7157-4df6-87ef-4982508b49cc-ageGroup:26-35:
        - 6.4
        - 15
        - 37.5
        - 32.2
        - 8.8
      515eb5c6-de73-40f5-bf9a-1200643cba44-ageGroup:26-35:
        - 0.5
        - 4.5
        - 20.8
        - 59.7
        - 14.6
      f0868346-3386-4c1d-8659-70cac7f5f83a-ageGroup:26-35:
        - 68.3
        - 11.9
        - 19.8
      fec8ed72-2275-423e-928d-d6683e720cab-ageGroup:26-35:
        - 37
        - 44.9
        - 18.1
      fac8ce7a-1654-4517-94a3-9f6e5a5280b3-ageGroup:26-35:
        - 19.8
        - 67.5
        - 12.6
      13a2c7d0-b480-4cf4-946e-b54d19e065a2-ageGroup:26-35:
        - 43.4
        - 31
        - 19.6
        - 6
      13a250db-ed4b-4c30-b44f-d011191136b2-ageGroup:26-35:
        - 61.3
        - 27.4
        - 7.4
        - 2.6
        - 1.2
      49aaef31-00eb-40e1-ac68-a1b388d81ca9-ageGroup:26-35:
        - 14.8
        - 43.9
        - 18.1
        - 12.6
        - 10.5
      75cce6ea-4a31-4103-a791-90e6db9ecd8f-ageGroup:26-35:
        - 16
        - 28.4
        - 24.6
        - 16.5
        - 14.6
      249238a9-3050-4e7c-a3d4-ef799733b865-ageGroup:26-35:
        - 8.8
        - 17.9
        - 25.1
        - 27
        - 21.2
      fee867c7-70e2-46ae-98e0-3dd3dd2865f6-ageGroup:26-35:
        - 43.9
        - 34.4
        - 11.5
        - 7.4
        - 2.9
      b9a2819d-9924-4172-99d5-7a3630022d4b-ageGroup:26-35:
        - 22
        - 39.1
        - 18.9
        - 14.3
        - 5.7
      e0b7bdbf-753b-48c2-9760-615a24ebe1f0-ageGroup:26-35:
        - 56.8
        - 20.8
        - 18.9
        - 3.6
      471504dc-486c-4c3a-97fb-8b9a39026c6e-ageGroup:26-35:
        - 8.6
        - 24.4
        - 52.4
        - 14.6
      9307ab2b-c46e-488d-8144-0f3657bf99f9-ageGroup:26-35:
        - 38.3
        - 15.6
        - 43.8
        - 2.4
      d1e7db5c-b64f-4255-8654-03efcb49f232-ageGroup:26-35:
        - 31.4
        - 44.4
        - 18
        - 6.2
      a2da635f-73e2-437a-b087-14de27d01e71-ageGroup:26-35:
        - 69.5
        - 20.1
        - 9.4
        - 1
      deaf0310-f471-4a48-b708-c1b832b3b07f-ageGroup:26-35:
        - 17.5
        - 38.6
        - 14.1
        - 18
        - 11.8
      ae9d3aad-cd36-45dc-8b84-1506f01e9b44-ageGroup:26-35:
        - 18
        - 35.7
        - 15.3
        - 17.3
        - 13.7
      e8d2fb10-f00d-4037-9252-37c5110544b4-ageGroup:26-35:
        - 13.9
        - 21.8
        - 19.7
        - 23.7
        - 20.9
      f9d8b140-b42d-4be6-8605-c1da8567816c-ageGroup:26-35:
        - 20.4
        - 26.6
        - 19.4
        - 18.2
        - 15.3
      15497069-f42b-44cb-8fb6-7bdcfaea6f86-ageGroup:26-35:
        - 36
        - 34.1
        - 12
        - 10.6
        - 7.4
      4af2da82-87f3-465f-9d6c-bb71b31b7f17-ageGroup:26-35:
        - 7.4
        - 11.8
        - 13.4
        - 30.7
        - 36.7
      05cb1e2e-a790-41c3-b899-0dec305fe818-ageGroup:26-35:
        - 3.4
        - 4.8
        - 9.1
        - 21.1
        - 61.6
      59d425dc-ae24-4de4-aa8e-510e1dc3a7e9-ageGroup:26-35:
        - 64.5
        - 25.2
        - 6.5
        - 2.2
        - 1.7
      2565f6c0-872d-4bcf-b772-cfc35fe0290f-ageGroup:26-35:
        - 66.2
        - 26.6
        - 5
        - 2.2
        - 0
      19bdbb9d-55e7-4325-92c4-e904b38e010c-ageGroup:26-35:
        - 21.8
        - 78.2
      c807fb39-7c68-4629-bf2e-5b20bf73b3f6-ageGroup:26-35:
        - 33.8
        - 17.5
        - 48.7
      2e3c16db-072c-4129-b714-01ea61167353-ageGroup:26-35:
        - 80.6
        - 19.4
      f9aaefee-0155-419f-83b3-5c8009c25d90-ageGroup:26-35:
        - 6.2
        - 68.3
        - 11
        - 14.4
      16290c47-29d8-4928-9331-4d694ce494a6-ageGroup:26-35:
        - 9.1
        - 67.6
        - 9.8
        - 13.4
      89b8ff63-8cf7-42cb-a06e-b72232772973-ageGroup:26-35:
        - 10.3
        - 73.4
        - 3.4
        - 12.9
      3ff1c1c6-523e-4555-a7df-35a96224f343-ageGroup:26-35:
        - 22.8
        - 45.4
        - 22.1
        - 9.6
      4d85b7fe-c1a8-47f4-843f-74eac3aaaeb5-ageGroup:26-35:
        - 5
        - 8.9
        - 14.9
        - 33.9
        - 37.3
      5258fc4e-10cf-464d-ac27-d7c05b221be7-ageGroup:26-35:
        - 20
        - 32.5
        - 36.5
        - 7.5
        - 3.6
      ae843d50-4b05-4a4c-880d-ad8a9ed7e2c7-ageGroup:26-35:
        - 20
        - 40.4
        - 28.4
        - 7.7
        - 3.6
      6c8f0fca-ab17-40e4-8581-9728d91cf993-ageGroup:26-35:
        - 53.4
        - 35.8
        - 8.4
        - 2.4
        - 0
      96e0211f-6222-46f8-b587-8b40f1b8420b-ageGroup:26-35:
        - 1
        - 2.4
        - 4.1
        - 17.5
        - 75
      832e4543-043b-419e-afec-00d795419297-ageGroup:26-35:
        - 0.2
        - 2.6
        - 5.5
        - 20.7
        - 70.9
      ecba93d1-4204-4195-8f4d-838fbd517889-ageGroup:26-35:
        - 0.2
        - 0.7
        - 1.9
        - 96.2
        - 1
      1a48f05a-f36d-4c7a-8532-f51c8d645196-ageGroup:26-35:
        - 8.2
        - 79.3
        - 7.7
        - 4.8
      b8e022eb-be4f-4e02-a346-739c01ca32ac-ageGroup:26-35:
        - 24.3
        - 34.1
        - 35.3
        - 6.3
      4eea4448-2896-4d6f-94c6-4dfdd597e77e-ageGroup:26-35:
        - 20.7
        - 33.9
        - 39.9
        - 5.5
      948ef76c-9b89-4461-84e3-43608d98c252-ageGroup:26-35:
        - 25.5
        - 34.4
        - 32
        - 8.2
      843a00ad-d036-4376-9a25-3ed62aedd5f1-ageGroup:26-35:
        - 24.9
        - 47.8
        - 16.4
        - 7.5
        - 3.4
      2fdf22c0-18d7-41f5-967e-11f580a06028-ageGroup:26-35:
        - 4.3
        - 17.6
        - 28.7
        - 33.6
        - 15.7
      62c24fd2-ecc7-496d-990a-1b5edd593615-ageGroup:26-35:
        - 13.5
        - 36.5
        - 35.5
        - 9.9
        - 4.6
      61e6f9ed-bd09-4c71-ac5d-293aea28db32-ageGroup:26-35:
        - 23.2
        - 50.2
        - 15.7
        - 10.1
        - 0.7
      84320916-86ae-4f0d-966d-b8bab4c62772-ageGroup:26-35:
        - 22.2
        - 38.4
        - 24.4
        - 11.8
        - 3.1
      b8b89356-961f-4131-b14c-93ae0aea2a96-ageGroup:26-35:
        - 9.7
        - 37
        - 30
        - 19.1
        - 4.3
      535d8f31-7417-43ce-91d1-93642026df23-ageGroup:26-35:
        - 1.2
        - 3.4
        - 5.8
        - 3.9
        - 85.7
      b6ca6705-f5ad-40e9-b7eb-6e207b34a0fa-ageGroup:26-35:
        - 10.9
        - 44.2
        - 22.2
        - 16.7
        - 6
      69e5c3bf-22bb-481b-a199-288f5b8a9f15-ageGroup:26-35:
        - 15.3
        - 42.4
        - 26.6
        - 11.4
        - 4.4
      e8770f98-0792-453f-a370-03cb63875992-ageGroup:26-35:
        - 41.2
        - 45.8
        - 13.1
      f7cecd2f-8afa-47ad-9a09-fbf5e8b0adfd-ageGroup:26-35:
        - 12.4
        - 26.9
        - 24
        - 31.6
        - 5.1
      f1576fce-5455-40fc-89d9-a3758959171d-ageGroup:26-35:
        - 4.9
        - 14.1
        - 24.5
        - 43.4
        - 13.1
      3249ff80-d73d-46c4-87bd-c40fb8252a1c-ageGroup:26-35:
        - 78.9
        - 17.7
        - 2.9
        - 0.5
      eadfc769-2907-4c59-be57-9ebf4d0c7d7a-ageGroup:26-35:
        - 97.1
        - 1.9
        - 1
      2c1a077d-d969-4df8-8bbd-9f569feb2774-ageGroup:26-35:
        - 0.5
        - 20.1
        - 79.4
      f5a834e3-55a7-42b6-b363-b5c768da3541-ageGroup:26-35:
        - 47.3
        - 43.2
        - 9.5
